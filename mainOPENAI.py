import os
import sys
import json
import jieba  # æ–°å¢ï¼šç”¨æ–¼ä¸­æ–‡æ–·è©
from fastapi import FastAPI, Request, HTTPException
from linebot import LineBotApi, WebhookHandler
from linebot.exceptions import InvalidSignatureError
from linebot.models import MessageEvent, TextMessage, TextSendMessage
from dotenv import load_dotenv
from openai import OpenAI

# --- RAG èˆ‡ æª¢ç´¢ ç›¸é—œå¥—ä»¶ ---
from langchain_huggingface import HuggingFaceEmbeddings # æ›´æ–°å¼•å…¥è·¯å¾‘
from langchain_community.vectorstores import FAISS
from langchain_core.documents import Document
from langchain_community.retrievers import BM25Retriever
from langchain.retrievers import EnsembleRetriever

# 1. è¼‰å…¥ç’°å¢ƒè®Šæ•¸
load_dotenv()

channel_secret = os.getenv('LINE_CHANNEL_SECRET')
channel_access_token = os.getenv('LINE_CHANNEL_ACCESS_TOKEN')
openai_api_key = os.getenv('OPENAI_API_KEY')

# è¨­å®šæ¨¡å‹åç¨± (ç›®å‰ OpenAI æœ€æ–°ç‚º gpt-4oï¼Œè‹¥æœªä¾† gpt-5.2 ç™¼å¸ƒå¯åœ¨æ­¤ä¿®æ”¹)
OPENAI_MODEL = "gpt-4o" 

if not all([channel_secret, channel_access_token, openai_api_key]):
    print("éŒ¯èª¤ï¼šè«‹ç¢ºèª .env æª”æ¡ˆä¸­å·²è¨­å®š LINE å¯†é‘°èˆ‡ OPENAI_API_KEY")
    sys.exit(1)

# 2. åˆå§‹åŒ– LINE Bot èˆ‡ OpenAI Client
line_bot_api = LineBotApi(channel_access_token)
handler = WebhookHandler(channel_secret)
client = OpenAI(api_key=openai_api_key)

# ==========================================
# [AI æ•™æˆé‡é»æ•™å­¸] RAG æ··åˆæª¢ç´¢ç³»çµ±åˆå§‹åŒ–
# ==========================================
print("æ­£åœ¨å»ºç«‹ RAG æ··åˆæª¢ç´¢ç³»çµ± (FAISS + BM25)...")

ensemble_retriever = None

# å®šç¾©ä¸­æ–‡æ–·è©å‡½æ•¸ (çµ¦ BM25 ä½¿ç”¨ï¼Œè§£æ±ºä¸­æ–‡é»åœ¨ä¸€èµ·å°è‡´æª¢ç´¢ä¸åˆ°çš„å•é¡Œ)
def chinese_tokenizer(text):
    return list(jieba.cut(text))

try:
    documents = []
    knowledge_file = "knowledgeNEW.jsonl"
    
    if not os.path.exists(knowledge_file):
        print(f"è­¦å‘Šï¼šæ‰¾ä¸åˆ° {knowledge_file}ï¼Œå°‡ä½¿ç”¨ç©ºè³‡æ–™ã€‚")
    else:
        with open(knowledge_file, "r", encoding="utf-8") as f:
            for line_number, line in enumerate(f, 1):
                line = line.strip()
                if not line: continue
                try:
                    data = json.loads(line)
                    # å®¹éŒ¯è™•ç†ï¼šæ”¯æ´ symptom/instruction å…©ç¨®æ¬„ä½å‘½å
                    instruction = data.get('symptom', data.get('instruction', ''))
                    response = data.get('solution', data.get('response', ''))
                    
                    # çµ„åˆå…§å®¹ä¾›æª¢ç´¢
                    page_content = f"æ•…éšœç—‡ç‹€ï¼š{instruction}\næ’é™¤æ–¹æ³•ï¼š{response}"
                    
                    doc = Document(
                        page_content=page_content,
                        metadata={"source": knowledge_file, "row": line_number}
                    )
                    documents.append(doc)
                except json.JSONDecodeError:
                    print(f"è­¦å‘Šï¼šç¬¬ {line_number} è¡Œæ ¼å¼éŒ¯èª¤ï¼Œå·²è·³éã€‚")

    docs = documents
    print(f"æˆåŠŸè¼‰å…¥ {len(docs)} æ¢çŸ¥è­˜ç‰‡æ®µï¼")

    if docs:
        # A. èªæ„æª¢ç´¢ (Vector Search) - ä½¿ç”¨æœ¬åœ° BGE-M3 æ¨¡å‹
        print("æ­£åœ¨è¼‰å…¥ Embedding æ¨¡å‹ (BAAI/bge-m3)...")
        embeddings = HuggingFaceEmbeddings(model_name="BAAI/bge-m3")
        
        vector_db = FAISS.from_documents(docs, embeddings)
        faiss_retriever = vector_db.as_retriever(search_kwargs={"k": 3})

        # B. é—œéµå­—æª¢ç´¢ (Keyword Search) - BM25 + Jieba æ–·è©
        print("æ­£åœ¨å»ºç«‹ BM25 ç´¢å¼• (å« Jieba æ–·è©)...")
        bm25_retriever = BM25Retriever.from_documents(
            docs,
            preprocess_func=chinese_tokenizer  # é—œéµä¿®æ­£ï¼šåŠ å…¥ä¸­æ–‡æ–·è©
        )
        bm25_retriever.k = 3

        # C. æ··åˆæª¢ç´¢ (Ensemble)
        ensemble_retriever = EnsembleRetriever(
            retrievers=[bm25_retriever, faiss_retriever],
            weights=[0.5, 0.5] # æ¬Šé‡å¯ä¾å¯¦éš›æ¸¬è©¦èª¿æ•´
        )
        print("æ··åˆæª¢ç´¢ç³»çµ± (Hybrid Search) å»ºç«‹å®Œæˆï¼")
    else:
        print("è­¦å‘Šï¼šæ²’æœ‰è¼‰å…¥ä»»ä½•æ–‡ä»¶ï¼ŒçŸ¥è­˜åº«ç‚ºç©ºã€‚")

except Exception as e:
    print(f"RAG åˆå§‹åŒ–å¤±æ•—: {e}")
    # ä¸å¼·åˆ¶é€€å‡ºï¼Œè®“ Server ä»èƒ½å•Ÿå‹•ï¼Œä½†æª¢ç´¢åŠŸèƒ½æœƒå¤±æ•ˆ
    pass

app = FastAPI()

@app.post("/callback")
async def callback(request: Request):
    signature = request.headers['X-Line-Signature']
    body = await request.body()
    try:
        handler.handle(body.decode(), signature)
    except InvalidSignatureError:
        raise HTTPException(status_code=400, detail="Invalid signature")
    return 'OK'

@handler.add(MessageEvent, message=TextMessage)
def handle_message(event):
    user_msg = event.message.text.strip()
    print(f"æ”¶åˆ°ä½¿ç”¨è€…è¨Šæ¯: {user_msg}")

    try:
        # --- [1. RAG æ··åˆæª¢ç´¢éšæ®µ] ---
        rag_context = ""
        if ensemble_retriever:
            # åŸ·è¡Œæ··åˆæª¢ç´¢
            found_docs = ensemble_retriever.invoke(user_msg)
            if found_docs:
                # å–å‰ 2 ç­†æœ€ç›¸é—œè³‡æ–™
                top_docs = found_docs[:2]
                rag_context = "\n\n".join([f"ã€æ•…éšœæ’é™¤æ‰‹å†Šåƒè€ƒè³‡æ–™ã€‘:\n{doc.page_content}" for i, doc in enumerate(top_docs)])
                # 
                print(f"--- ğŸ” æª¢ç´¢åˆ°çš„åƒè€ƒè³‡æ–™ ---\n{rag_context[:100]}...\n-----------------------------")
            else:
                print("--- ğŸ” æœªæª¢ç´¢åˆ°ç›¸é—œè³‡æ–™ ---")

        # --- [2. Prompt çµ„åˆéšæ®µ] ---
        system_prompt = (
            "ä½ æ˜¯ä¸€ä½è³‡æ·±çš„æ·é‹ç¶­ä¿®å°ˆå®¶ï¼Œè² è²¬å”åŠ©ç¶­ä¿®äººå“¡æ’é™¤æ•…éšœã€‚"
            "è«‹åš´æ ¼æ ¹æ“šæä¾›çµ¦ä½ çš„ã€æ•…éšœæ’é™¤æ‰‹å†Šã€‘ä¾†å›ç­”ä½¿ç”¨è€…çš„å•é¡Œã€‚"
            "å›ç­”è¦å‰‡ï¼š"
            "1. è‹¥åƒè€ƒè³‡æ–™ä¸­æœ‰å°æ‡‰çš„æ•…éšœä»£ç¢¼æˆ–ç—‡ç‹€ï¼Œè«‹åˆ—å‡ºå…·é«”çš„æ’é™¤æ­¥é©Ÿã€‚"
            "2. è‹¥åƒè€ƒè³‡æ–™èˆ‡å•é¡Œç„¡é—œæˆ–ä¸è¶³ä»¥å›ç­”ï¼Œè«‹æ˜ç¢ºå›ç­”ã€Œæ‰‹å†Šä¸­æŸ¥ç„¡æ­¤æ•…éšœè³‡æ–™ï¼Œå»ºè­°æŸ¥é–±å¯¦é«”æ‰‹å†Šæˆ–è¯ç¹«è¡Œæ§ä¸­å¿ƒã€ï¼Œåš´ç¦è‡ªè¡Œç·¨é€ ã€‚"
            "3. èªæ°£è«‹ä¿æŒå°ˆæ¥­ã€å†·éœï¼Œä¸¦ä½¿ç”¨ç¹é«”ä¸­æ–‡ã€‚"
        )

        if rag_context:
            user_content = f"åƒè€ƒè³‡æ–™ï¼š\n{rag_context}\n\nä½¿ç”¨è€…å•é¡Œï¼š{user_msg}"
        else:
            user_content = f"ä½¿ç”¨è€…å•é¡Œï¼š{user_msg} (æ³¨æ„ï¼šç³»çµ±æœªæª¢ç´¢åˆ°ç›¸é—œæ‰‹å†Šè³‡æ–™)"

        # --- [3. ChatGPT API å‘¼å«éšæ®µ] ---
        print(f"æ­£åœ¨å‘¼å« OpenAI API (Model: {OPENAI_MODEL})...")
        response = client.chat.completions.create(
            model=OPENAI_MODEL,  # ä½¿ç”¨è®Šæ•¸è¨­å®šçš„æ¨¡å‹
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_content}
            ],
            temperature=0.1, # é™ä½æº«åº¦ä»¥ç¢ºä¿å›ç­”åŸºæ–¼äº‹å¯¦
            max_tokens=600
        )

        final_reply = response.choices[0].message.content.strip()

    except Exception as e:
        print(f"ç³»çµ±éŒ¯èª¤: {e}")
        final_reply = "æŠ±æ­‰ï¼Œç›®å‰ç¶­ä¿®AIç³»çµ±é­é‡å…§éƒ¨éŒ¯èª¤ï¼Œè«‹é€šçŸ¥ç®¡ç†å“¡ã€‚"

    # å›è¦† LINE è¨Šæ¯
    line_bot_api.reply_message(
        event.reply_token,
        TextSendMessage(text=final_reply)
    )
    print("å·²å›è¦†ä½¿ç”¨è€…è¨Šæ¯ã€‚")